{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9808bc-0e9f-426a-b27a-f004f2ae56eb",
   "metadata": {},
   "source": [
    "Review by team member 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d0ca5-be0e-4a84-8c86-28fee7ac53f2",
   "metadata": {},
   "source": [
    "My tasks:\n",
    "\n",
    "- create a function generate_means_sequence(string collated_answers _path)\n",
    "  - Input: Path to the file collated_answers.txt.\n",
    "  - Output: List of 100 floats, representing the mean answer value per question(excluding unanswered questions marked as 0).\n",
    "  - Purpose: Process answer sequences (using extract_answers_sequencefrom Team Member 1), compute statistics, and identify patterns or regularities in answer distributions.\n",
    " \n",
    "\n",
    "\n",
    "- create a function visualize_data(string collated_answers _path, int n)\n",
    "  - Input: Path to the data folder and an integer n (1 or 2).\n",
    "  - Output: Visualizes the means sequence as a scatter plot (if n=1), a line plot (if n=2) with all lines for each individual answer file displayed simultaneously on an horizontal scale 1-100, or displays an error message (if n is neither 1 nor 2).\n",
    "  - Purpose: Provide visual insights into potential patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd373e75-7415-48fe-9d0c-8992a3eea505",
   "metadata": {},
   "source": [
    "Code demonstration:\n",
    "After running my code, a separate file is created in the output section, which shows the mean answer to questions 1 to 100. Depending on whether n = 1, or n = 2 for the visualise function, a scatter or line graph is produced for the results. Hence showing that the code is correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9ac2e-99e3-4e01-8702-3c03754a02d1",
   "metadata": {},
   "source": [
    "Analysis of Results: \n",
    "\n",
    "Are any answers consistently favoured? \n",
    "\n",
    "I would say no, based on the scatter plot, the mean answers seem quite evenly distributed between the first, second, third and fourth options. However, boxes 2 and 3 tend to have more averages directly on them, which is clearly because questions 1 and 4 would have to have entirely correct answers to average out at their exact values. \n",
    "\n",
    "Is there a recognisable pattern? \n",
    "\n",
    "Yes, there are 4 relatively strong lines of dots across each whole number value. This shows that there is quite a strong correlation between answers for each question. \n",
    "\n",
    "Are there any anomalies? \n",
    "\n",
    "There are two data points which you could consider anomalies, the first being Q52 with a mean of 3.39, which is pretty inconclusive between 3 and 4. The second being Q56, which is 1.46 and almost directly between 1 and 2, meaning that the people taking the test may have been unsure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dabff5-4c68-4809-b8ca-03c83275dffb",
   "metadata": {},
   "source": [
    "Discussion of Methodology:\n",
    "\n",
    "Function 1:\n",
    "\n",
    "Input:\n",
    "\n",
    "A path to the data/ folder containing the formatted answer files.\n",
    "\n",
    "Process:\n",
    "\n",
    "Create a list of 100 sublists for each question to store the selected answers.\n",
    "Iterates over all files named answers_respondent_*.txt.\n",
    "For each respondent, uses extract_answers_sequence() to get their answer list.\n",
    "For each question, appends the answer to question_data[], if it's not 0\n",
    "Calculates the mean of each sublist using np.mean() and stores the result in means_sequence.\n",
    "\n",
    "Output:\n",
    "A list of 100 mean values, outputs into a separate file under 'output'.\n",
    "\n",
    "Function 2: \n",
    "\n",
    "Input:\n",
    "\n",
    "A path to the data/ folder.\n",
    "\n",
    "An integer n:\n",
    "\n",
    "n=1: Produces a scatter plot, \n",
    "n=2: Produces a line plot.\n",
    "\n",
    "Shows the plot using matplotlib.pyplot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838e651-46ca-4671-8cf8-c2c27ec223bc",
   "metadata": {},
   "source": [
    "Limitations and assumptions:\n",
    "\n",
    "The main limitation is the visualisation of the line plot; it is very hard to follow what is going on, and I could not think of a way to fix this with so many lines. \n",
    "\n",
    "The predominant assumption is that the data is formatted well and that the code provided by my other team member was correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c589aa-f9f4-4d0a-84c0-b050df9aef70",
   "metadata": {},
   "source": [
    "Reflections on GitHub Collaboration;\n",
    "\n",
    "I successfully collaborated with 3 other team members, ensuring that I pushed, pulled and committed efficiently, attempting to make the repository flow well too with useful notes on the commits and file names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad7c6e-4e9a-44c4-aa46-af57165076dd",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "\n",
    "I feel as though my coding has improved significantly using numpy, os and good use of visualisations. I feel as though our efforts reflected the brief and that the project is overall successful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fdc6cb-9ab7-4523-b701-9161a5b91569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
