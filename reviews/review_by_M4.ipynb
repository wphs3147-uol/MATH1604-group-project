{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team member 4 Review\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My role\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Team Member 4, I was responsible for writing the integration script that runs the full data analysis pipeline for the multiple choice quiz data. My task was to combine the outputs of the other team members and produce meaningful results and visualisations using the collated_answers.txt file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some issues with integration\n",
    "\n",
    "The function extract_answers_sequence() in data_extraction_M1.py included a line that attempted to apply .lower() to a list, which caused it to crash so I rewrote this function in my code.\n",
    "\n",
    "The collate_answer_files() function from data_preparation_M2.py was implemented correctly to match the brief, which required handling remote cloud data. Since the final code was not meant to work with local data, and the final version used requests.get(). I was working with a locally extracted folder, I proceeded to write my code on the assumption that the collated_answers.txt file already existed.\n",
    "\n",
    "The generate_means_sequence() function from data_analysis_M3.py expected a folder of files rather than the single collated_answers.txt file so calling the function as written caused a NotADirectoryError. The accompanying visualize_data() function also relied on that broken input assumption.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions I took\n",
    "\n",
    "To meet the requirements of my role, I wrote my own version of generate_means_sequence() and visualize_data(). These accepted collated_answers.txt as input. I did not call broken functions and instead created replacements to ensure my integration script worked finally.\n",
    "\n",
    "I also generated a test collated_answers.txt file using mock data in the correct format (numerical answer values separated by * between respondents). This allowed me to demonstrate that my script works and produces the expected output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall reflection\n",
    "\n",
    "My script successfully reads collated_answers.txt, calculates the mean answer per question, and generates two visualisations, a scatter plot of mean answers and a line plot of respondent answer patterns. This task helped me practise working within constraints, debugging collaboratively produced code, and delivering a working final product even when other dependencies may not work as expected.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
